{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocesses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pqdm\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCODE\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscripts/06_analyze_frame_features/label_verb_noun_tool_mapping.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m reader:\n\u001b[1;32m     13\u001b[0m     label_verb_noun_tools_mapping \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(reader)\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sentence_transformers/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2.2.2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m __MODEL_HUB_ORGANIZATION__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msentence-transformers\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mLoggingHandler\u001b[39;00m \u001b[39mimport\u001b[39;00m LoggingHandler\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSentenceTransformer\u001b[39;00m \u001b[39mimport\u001b[39;00m SentenceTransformer\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sentence_transformers/datasets/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mNoDuplicatesDataLoader\u001b[39;00m \u001b[39mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mParallelSentencesDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m ParallelSentencesDataset\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sentence_transformers/datasets/DenoisingAutoEncoderDataset.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreaders\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mInputExample\u001b[39;00m \u001b[39mimport\u001b[39;00m InputExample\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtreebank\u001b[39;00m \u001b[39mimport\u001b[39;00m TreebankWordDetokenizer\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDenoisingAutoEncoderDataset\u001b[39;00m(Dataset):\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/nltk/__init__.py:133\u001b[0m\n\u001b[1;32m    125\u001b[0m     subprocess\u001b[39m.\u001b[39mPopen \u001b[39m=\u001b[39m _fake_Popen\n\u001b[1;32m    127\u001b[0m \u001b[39m###########################################################\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# TOP-LEVEL MODULES\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m###########################################################\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[39m# Import top-level functionality into top-level namespace\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcollocations\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecorators\u001b[39;00m \u001b[39mimport\u001b[39;00m decorator, memoize\n\u001b[1;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeatstruct\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/nltk/collocations.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_itertools\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# these two unused imports are referenced in collocations.doctest\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     BigramAssocMeasures,\n\u001b[1;32m     38\u001b[0m     ContingencyMeasures,\n\u001b[1;32m     39\u001b[0m     QuadgramAssocMeasures,\n\u001b[1;32m     40\u001b[0m     TrigramAssocMeasures,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspearman\u001b[39;00m \u001b[39mimport\u001b[39;00m ranks_from_scores, spearman_correlation\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprobability\u001b[39;00m \u001b[39mimport\u001b[39;00m FreqDist\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/nltk/metrics/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magreement\u001b[39;00m \u001b[39mimport\u001b[39;00m AnnotationTask\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maline\u001b[39;00m \u001b[39mimport\u001b[39;00m align\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39massociation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     BigramAssocMeasures,\n\u001b[1;32m     20\u001b[0m     ContingencyMeasures,\n\u001b[1;32m     21\u001b[0m     NgramAssocMeasures,\n\u001b[1;32m     22\u001b[0m     QuadgramAssocMeasures,\n\u001b[1;32m     23\u001b[0m     TrigramAssocMeasures,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfusionmatrix\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfusionMatrix\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     binary_distance,\n\u001b[1;32m     28\u001b[0m     custom_distance,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     presence,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/nltk/metrics/association.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m _SMALL \u001b[39m=\u001b[39m \u001b[39m1e-20\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m fisher_exact\n\u001b[1;32m     27\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfisher_exact\u001b[39m(\u001b[39m*\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs):\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/stats/__init__.py:608\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m \n\u001b[1;32m    604\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 608\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    609\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[1;32m    610\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/stats/_stats_py.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m NumpyVersion\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m suppress_warnings\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m cdist\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m _measurements\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m (check_random_state, MapWrapper, _get_nan,\n\u001b[1;32m     42\u001b[0m                               rng_integers, _rename_parameter, _contains_nan)\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/spatial/__init__.py:110\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m=============================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m   QhullError\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_kdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_ckdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_qhull\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/spatial/_kdtree.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Released under the scipy license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_ckdtree\u001b[39;00m \u001b[39mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[1;32m      6\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mminkowski_distance_p\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mminkowski_distance\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mdistance_matrix\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mRectangle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKDTree\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminkowski_distance_p\u001b[39m(x, y, p\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n",
      "File \u001b[0;32m_ckdtree.pyx:12\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/__init__.py:287\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matrix_io\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[1;32m    289\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    291\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    292\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    293\u001b[0m )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/csgraph/__init__.py:185\u001b[0m\n\u001b[1;32m    157\u001b[0m __docformat__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrestructuredtext en\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mconnected_components\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mlaplacian\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshortest_path\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mcsgraph_to_masked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    183\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mNegativeCycleError\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_laplacian\u001b[39;00m \u001b[39mimport\u001b[39;00m laplacian\n\u001b[1;32m    186\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_shortest_path\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    188\u001b[0m     NegativeCycleError\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_traversal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    193\u001b[0m )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     10\u001b[0m \u001b[39m###############################################################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Graph laplacian\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlaplacian\u001b[39m(\n\u001b[1;32m     13\u001b[0m     csgraph,\n\u001b[1;32m     14\u001b[0m     normed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     symmetrized\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ):\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/linalg/__init__.py:120\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dsolve\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miterative\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mminres\u001b[39;00m \u001b[39mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlgmres\u001b[39;00m \u001b[39mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/scipy/sparse/linalg/_isolve/iterative.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m \u001b[39mimport\u001b[39;00m dedent\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _iterative\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pqdm.processes import pqdm\n",
    "from typing import Dict, List, Tuple\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "with open(os.path.join(os.environ[\"CODE\"], \"scripts/06_analyze_frame_features/label_verb_noun_tool_mapping.json\"), \"r\") as reader:\n",
    "    label_verb_noun_tools_mapping = json.load(reader)\n",
    "\n",
    "with open(os.path.join(os.environ[\"SCRATCH\"], \"ego4d_data/v2/analysis_data\", \"clip_id_frame_id_blip2_verb_noun_tool_pair_mapping.pickle\"), \"rb\") as reader:\n",
    "    clip_id_frame_id_blip2_verb_noun_tool_pair_mapping = pickle.load(reader)\n",
    "\n",
    "with open(os.path.join(os.environ[\"SCRATCH\"], \"ego4d_data/v2/analysis_data\", \"analysis_data.pickle\"), \"rb\") as reader:\n",
    "    clip_id_frame_id_ground_truth_labels_mapping = pickle.load(reader)[\"clip_id_frame_id_labels_mapping\"]\n",
    "\n",
    "sbert = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_ground_truth_labels = [\"background\"] + sorted(list(label_verb_noun_tools_mapping.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id_frame_id_ground_truth_label_indices_mapping = dict()\n",
    "for clip_id, frame_id_ground_truth_labels_mapping in clip_id_frame_id_ground_truth_labels_mapping.items():\n",
    "    if list(clip_id_frame_id_ground_truth_labels_mapping[clip_id][0])[0] == \"no_annotation\":\n",
    "        continue\n",
    "    clip_id_frame_id_ground_truth_label_indices_mapping[clip_id] = dict()\n",
    "    for frame_id, ground_truth_labels in frame_id_ground_truth_labels_mapping.items():\n",
    "        clip_id_frame_id_ground_truth_label_indices_mapping[clip_id][frame_id] = []\n",
    "        for ground_truth_label in ground_truth_labels:\n",
    "            clip_id_frame_id_ground_truth_label_indices_mapping[clip_id][frame_id].append(distinct_ground_truth_labels.index(ground_truth_label))\n",
    "del clip_id_frame_id_ground_truth_labels_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1903/2495 [2:41:05<49:22,  5.00s/it]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(os.environ[\"SCRATCH\"], \"ego4d_data/v2/analysis_data\", ), \"rb\") as reader:\n",
    "    clip_id_frame_id_asl_predicted_label_indices_and_scores_mapping = pickle.load(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sbert_cosine_similarities(blip2_sbert_embeddings: List[np.array], label_sbert_embeddings: List[np.array]):\n",
    "    max_cosine_similarity = 0.0\n",
    "    for blip2_sbert_embedding in blip2_sbert_embeddings:\n",
    "        for label_sbert_embedding in label_sbert_embeddings:\n",
    "            current_cosine_similarity = (np.dot(blip2_sbert_embedding, label_sbert_embedding)/(np.linalg.norm(blip2_sbert_embedding) * np.linalg.norm(label_sbert_embedding)) + 1.0) / 2.0\n",
    "            max_cosine_similarity = max(max_cosine_similarity, current_cosine_similarity)\n",
    "    return max_cosine_similarity\n",
    "\n",
    "\n",
    "def nontemporal_dictionary_matching_for_given_clip(clip_id: str, frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping: Dict[str, List[Tuple[str, str, str]]], label_verb_noun_tools_mapping: Dict[str, List[Tuple[str, str, str]]]):\n",
    "    frame_id_predicted_label_indices_and_scores = dict()\n",
    "\n",
    "    for frame_id, blip2_question_answer_verb_noun_tool_pairs_mapping in frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "        frame_id_predicted_label_indices_and_scores[frame_id] = dict()\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            if label_index == 0:\n",
    "                for blip2_question, blip2_answer_verb_noun_tool_pairs in blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "                    blip2_verb_noun_tool_pairs = blip2_answer_verb_noun_tool_pairs[1]\n",
    "                    if len(blip2_verb_noun_tool_pairs) == 0:\n",
    "                        frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 1.0\n",
    "                    else:\n",
    "                        frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 0.0\n",
    "            else:\n",
    "                if label_index not in frame_id_predicted_label_indices_and_scores[frame_id].keys():\n",
    "                    frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 0.0\n",
    "                \n",
    "                label = distinct_ground_truth_labels[label_index]\n",
    "                label_verb_noun_tools = label_verb_noun_tools_mapping[label]\n",
    "\n",
    "                for label_verb_noun_tool in label_verb_noun_tools:\n",
    "                    label_verb = label_verb_noun_tool[0].replace(\" \", \"\")\n",
    "                    label_noun = label_verb_noun_tool[1].replace(\" \", \"\")\n",
    "                    label_tool = label_verb_noun_tool[2].replace(\" \", \"\")\n",
    "                    for blip2_question, blip2_answer_verb_noun_tool_pairs in blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "                        blip2_answer = blip2_answer_verb_noun_tool_pairs[0]\n",
    "                        blip2_verb_noun_tool_pairs = blip2_answer_verb_noun_tool_pairs[1]\n",
    "                        for blip2_verb_noun_tool_pair in blip2_verb_noun_tool_pairs:\n",
    "                            blip2_verb = blip2_verb_noun_tool_pair[0].replace(\" \", \"\")\n",
    "                            blip2_noun = blip2_verb_noun_tool_pair[1].replace(\" \", \"\")\n",
    "                            blip2_tool = blip2_verb_noun_tool_pair[2].replace(\" \", \"\")\n",
    "                            if label_verb == blip2_verb and label_noun == blip2_noun and label_tool == blip2_tool:\n",
    "                                frame_id_predicted_label_indices_and_scores[frame_id][label_index] = max(frame_id_predicted_label_indices_and_scores[frame_id][label_index], 1.00)\n",
    "                            elif label_verb == blip2_verb and label_noun == blip2_noun:\n",
    "                                frame_id_predicted_label_indices_and_scores[frame_id][label_index] = max(frame_id_predicted_label_indices_and_scores[frame_id][label_index], 0.75)\n",
    "                            elif label_verb == blip2_verb and label_tool == blip2_tool:\n",
    "                                frame_id_predicted_label_indices_and_scores[frame_id][label_index] = max(frame_id_predicted_label_indices_and_scores[frame_id][label_index], 0.50)\n",
    "                            elif label_verb == blip2_verb:\n",
    "                                frame_id_predicted_label_indices_and_scores[frame_id][label_index] = max(frame_id_predicted_label_indices_and_scores[frame_id][label_index], 0.25)\n",
    "\n",
    "        # Normalize scores per frame so that their sum is equal to 1.0.\n",
    "        sum_scores = 0.0\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            sum_scores += frame_id_predicted_label_indices_and_scores[frame_id][label_index]\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            frame_id_predicted_label_indices_and_scores[frame_id][label_index] = frame_id_predicted_label_indices_and_scores[frame_id][label_index] / float(sum_scores)\n",
    "\n",
    "    return clip_id, frame_id_predicted_label_indices_and_scores\n",
    "\n",
    "\n",
    "def nontemporal_sbert_embedding_for_given_clip(clip_id: str, frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping: Dict[str, List[Tuple[str, str, str]]], label_verb_noun_tools_mapping: Dict[str, List[Tuple[str, str, str]]]):\n",
    "    label_verb_noun_tool_sbert_embeddings_mapping = dict()\n",
    "    label_verb_noun_sbert_embeddings_mapping = dict()\n",
    "    label_verb_tool_sbert_embeddings_mapping = dict()\n",
    "    label_verb_sbert_embeddings_mapping = dict()\n",
    "\n",
    "    for label, label_verb_noun_tools in label_verb_noun_tools_mapping.items():\n",
    "        label_index = distinct_ground_truth_labels.index(label)\n",
    "        if label_index not in label_verb_noun_tool_sbert_embeddings_mapping.keys():\n",
    "            label_verb_noun_tool_sbert_embeddings_mapping[label_index] = []\n",
    "        if label_index not in label_verb_noun_sbert_embeddings_mapping.keys():\n",
    "            label_verb_noun_sbert_embeddings_mapping[label_index] = []\n",
    "        if label_index not in label_verb_tool_sbert_embeddings_mapping.keys():\n",
    "            label_verb_tool_sbert_embeddings_mapping[label_index] = []\n",
    "        if label_index not in label_verb_sbert_embeddings_mapping.keys():\n",
    "            label_verb_sbert_embeddings_mapping[label_index] = []\n",
    "\n",
    "        for label_verb_noun_tool in label_verb_noun_tools:\n",
    "            label_verb = label_verb_noun_tool[0]\n",
    "            label_noun = label_verb_noun_tool[1]\n",
    "            label_tool = label_verb_noun_tool[2]\n",
    "            if label_noun == \"NaN\":\n",
    "                label_noun = \"something\"\n",
    "            if label_tool == \"NaN\":\n",
    "                label_tool = \"a tool\"\n",
    "\n",
    "            label_sbert_embeddings = sbert.encode([\n",
    "                f\"{label_verb} {label_noun} using {label_tool}\",\n",
    "                f\"{label_verb} {label_noun}\",\n",
    "                f\"{label_verb} using {label_tool}\",\n",
    "                f\"{label_verb}\"\n",
    "            ])\n",
    "\n",
    "            label_verb_noun_tool_sbert_embeddings_mapping[label_index].append(label_sbert_embeddings[0])\n",
    "            label_verb_noun_sbert_embeddings_mapping[label_index].append(label_sbert_embeddings[1])\n",
    "            label_verb_tool_sbert_embeddings_mapping[label_index].append(label_sbert_embeddings[2])\n",
    "            label_verb_sbert_embeddings_mapping[label_index].append(label_sbert_embeddings[3])\n",
    "\n",
    "    frame_id_blip2_answer_sbert_embeddings_mapping = dict()\n",
    "    frame_id_blip2_verb_noun_tool_sbert_embeddings_mapping = dict()\n",
    "    frame_id_blip2_verb_noun_sbert_embeddings_mapping = dict()\n",
    "    frame_id_blip2_verb_tool_sbert_embeddings_mapping = dict()\n",
    "    frame_id_blip2_verb_sbert_embeddings_mapping = dict()\n",
    "\n",
    "    for frame_id, blip2_question_answer_verb_noun_tool_pairs_mapping in frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "        frame_id_blip2_answer_sbert_embeddings_mapping[frame_id] = []\n",
    "        frame_id_blip2_verb_noun_tool_sbert_embeddings_mapping[frame_id] = []\n",
    "        frame_id_blip2_verb_noun_sbert_embeddings_mapping[frame_id] = []\n",
    "        frame_id_blip2_verb_tool_sbert_embeddings_mapping[frame_id] = []\n",
    "        frame_id_blip2_verb_sbert_embeddings_mapping[frame_id] = []\n",
    "        for blip2_question, blip2_answer_verb_noun_tool_pairs in blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "            for index, blip2_answer_verb_noun_tool_pair in enumerate(blip2_answer_verb_noun_tool_pairs[1]):\n",
    "                blip2_verb = blip2_answer_verb_noun_tool_pair[0]\n",
    "                blip2_noun = blip2_answer_verb_noun_tool_pair[1]\n",
    "                blip2_tool = blip2_answer_verb_noun_tool_pair[2]\n",
    "                if blip2_noun == \"NaN\":\n",
    "                    blip2_noun = \"something\"\n",
    "                if blip2_tool == \"NaN\":\n",
    "                    blip2_tool = \"a tool\"\n",
    "\n",
    "                if index == 0:\n",
    "                    blip2_answer = blip2_answer_verb_noun_tool_pairs[0]\n",
    "                    blip2_sbert_embeddings = sbert.encode([\n",
    "                        f\"{blip2_verb} {blip2_noun} using {blip2_tool}\",\n",
    "                        f\"{blip2_verb} {blip2_noun}\",\n",
    "                        f\"{blip2_verb} using {blip2_tool}\",\n",
    "                        f\"{blip2_verb}\",\n",
    "                        f\"{blip2_answer}\"\n",
    "                    ])\n",
    "                    frame_id_blip2_verb_noun_tool_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[0])\n",
    "                    frame_id_blip2_verb_noun_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[1])\n",
    "                    frame_id_blip2_verb_tool_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[2])\n",
    "                    frame_id_blip2_verb_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[3])\n",
    "                    frame_id_blip2_answer_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[4])\n",
    "                else:\n",
    "                    blip2_sbert_embeddings = sbert.encode([\n",
    "                        f\"{blip2_verb} {blip2_noun} using {blip2_tool}\",\n",
    "                        f\"{blip2_verb} {blip2_noun}\",\n",
    "                        f\"{blip2_verb} using {blip2_tool}\",\n",
    "                        f\"{blip2_verb}\"\n",
    "                    ])\n",
    "                    frame_id_blip2_verb_noun_tool_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[0])\n",
    "                    frame_id_blip2_verb_noun_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[1])\n",
    "                    frame_id_blip2_verb_tool_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[2])\n",
    "                    frame_id_blip2_verb_sbert_embeddings_mapping[frame_id].append(blip2_sbert_embeddings[3])\n",
    "\n",
    "    frame_id_predicted_label_indices_and_scores = dict()\n",
    "    for frame_id in frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping.keys():\n",
    "        frame_id_predicted_label_indices_and_scores[frame_id] = dict()\n",
    "\n",
    "        blip2_answer_sbert_embeddings = frame_id_blip2_answer_sbert_embeddings_mapping[frame_id]\n",
    "        blip2_verb_noun_tool_sbert_embeddings = frame_id_blip2_verb_noun_tool_sbert_embeddings_mapping[frame_id]\n",
    "        blip2_verb_noun_sbert_embeddings = frame_id_blip2_verb_noun_sbert_embeddings_mapping[frame_id]\n",
    "        blip2_verb_tool_sbert_embeddings = frame_id_blip2_verb_tool_sbert_embeddings_mapping[frame_id]\n",
    "        blip2_verb_sbert_embeddings = frame_id_blip2_verb_sbert_embeddings_mapping[frame_id]\n",
    "\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            if label_index == 0:\n",
    "                for blip2_question, blip2_answer_verb_noun_tool_pairs in blip2_question_answer_verb_noun_tool_pairs_mapping.items():\n",
    "                    blip2_verb_noun_tool_pairs = blip2_answer_verb_noun_tool_pairs[1]\n",
    "                    if len(blip2_verb_noun_tool_pairs) == 0:\n",
    "                        frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 1.0\n",
    "                    else:\n",
    "                        frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 0.0\n",
    "            else:\n",
    "                if label not in frame_id_predicted_label_indices_and_scores[frame_id].keys():\n",
    "                    frame_id_predicted_label_indices_and_scores[frame_id][label_index] = 0.0\n",
    "\n",
    "                label_verb_noun_tool_sbert_embeddings = label_verb_noun_tool_sbert_embeddings_mapping[label_index]\n",
    "                label_verb_noun_sbert_embeddings = label_verb_noun_sbert_embeddings_mapping[label_index]\n",
    "                label_verb_tool_sbert_embeddings = label_verb_tool_sbert_embeddings_mapping[label_index]\n",
    "                label_verb_sbert_embeddings = label_verb_sbert_embeddings_mapping[label_index]\n",
    "\n",
    "                frame_id_predicted_label_indices_and_scores[frame_id][label_index] = max([\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_answer_sbert_embeddings, label_sbert_embeddings=label_verb_noun_tool_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_answer_sbert_embeddings, label_sbert_embeddings=label_verb_noun_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_answer_sbert_embeddings, label_sbert_embeddings=label_verb_tool_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_answer_sbert_embeddings, label_sbert_embeddings=label_verb_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_verb_noun_tool_sbert_embeddings, label_sbert_embeddings=label_verb_noun_tool_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_verb_noun_sbert_embeddings, label_sbert_embeddings=label_verb_noun_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_verb_tool_sbert_embeddings, label_sbert_embeddings=label_verb_tool_sbert_embeddings),\n",
    "                    calculate_sbert_cosine_similarities(blip2_sbert_embeddings=blip2_verb_sbert_embeddings, label_sbert_embeddings=label_verb_sbert_embeddings)\n",
    "                ])\n",
    "\n",
    "        # Normalize scores per frame so that their sum is equal to 1.0.\n",
    "        sum_scores = 0.0\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            sum_scores += frame_id_predicted_label_indices_and_scores[frame_id][label_index]\n",
    "        for label_index in range(len(distinct_ground_truth_labels)):\n",
    "            frame_id_predicted_label_indices_and_scores[frame_id][label_index] = frame_id_predicted_label_indices_and_scores[frame_id][label_index] / float(sum_scores)\n",
    "\n",
    "    return clip_id, frame_id_predicted_label_indices_and_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_verb_noun_tool_match_ratio_mapping = dict()\n",
    "label_verb_noun_match_ratio_mapping = dict()\n",
    "label_verb_tool_match_ratio_mapping = dict()\n",
    "label_verb_match_ratio_mapping = dict()\n",
    "label_verb_noun_tool_count_mapping = dict()\n",
    "\n",
    "background_match_count = 0\n",
    "background_count = 0\n",
    "\n",
    "for clip_id, frame_id_ground_truth_label_indices_mapping in clip_id_frame_id_ground_truth_label_indices_mapping.items():\n",
    "    for frame_id, label_indices in frame_id_ground_truth_label_indices_mapping.items():\n",
    "        blip2_question_answer_verb_noun_tool_mapping = clip_id_frame_id_blip2_verb_noun_tool_pair_mapping[clip_id][int((frame_id // 6) * 6)]\n",
    "        for label_index in label_indices:\n",
    "            for dictionary in [label_verb_noun_tool_match_ratio_mapping, label_verb_noun_match_ratio_mapping, label_verb_tool_match_ratio_mapping, label_verb_match_ratio_mapping, label_verb_noun_tool_count_mapping]:\n",
    "                if label_index not in dictionary.keys() and label_index != 0:\n",
    "                    dictionary[label_index] = 0\n",
    "\n",
    "            label = distinct_ground_truth_labels[label_index]\n",
    "\n",
    "            if label == \"background\":\n",
    "                for blip2_question, blip2_answer_verb_noun_tools in blip2_question_answer_verb_noun_tool_mapping.items():\n",
    "                    blip2_answer = blip2_answer_verb_noun_tools[0]\n",
    "                    blip2_verb_noun_tools = blip2_answer_verb_noun_tools[1]\n",
    "                    if len(blip2_verb_noun_tools) == 0:\n",
    "                        background_match_count += 1\n",
    "                    background_count += 1\n",
    "            else:\n",
    "                label_verb_noun_tools = label_verb_noun_tools_mapping[label]\n",
    "                blip2_question_answer_verb_noun_tool_mapping = clip_id_frame_id_blip2_verb_noun_tool_pair_mapping[clip_id][(frame_id // 6) * 6]\n",
    "                for blip2_question, blip2_answer_verb_noun_tools in blip2_question_answer_verb_noun_tool_mapping.items():\n",
    "                    blip2_answer = blip2_answer_verb_noun_tools[0]\n",
    "                    blip2_verb_noun_tools = blip2_answer_verb_noun_tools[1]\n",
    "\n",
    "                    for blip2_verb_noun_tool in blip2_verb_noun_tools:\n",
    "                        blip2_verb = blip2_verb_noun_tool[0]\n",
    "                        blip2_noun = blip2_verb_noun_tool[1]\n",
    "                        blip2_tool = blip2_verb_noun_tool[2]\n",
    "\n",
    "                        for label_verb_noun_tool in label_verb_noun_tools:\n",
    "                            label_verb = label_verb_noun_tool[0]\n",
    "                            label_noun = label_verb_noun_tool[1]\n",
    "                            label_tool = label_verb_noun_tool[2]\n",
    "                            label_verb_noun_tool_count_mapping[label_index] += 1\n",
    "                            if blip2_verb == label_verb and blip2_noun == label_noun and blip2_tool == label_tool:\n",
    "                                label_verb_noun_tool_match_ratio_mapping[label_index] += 1\n",
    "                            elif blip2_verb == label_verb and blip2_noun == label_noun:\n",
    "                                label_verb_noun_match_ratio_mapping[label_index] += 1\n",
    "                            elif blip2_verb == label_verb and blip2_tool == label_tool:\n",
    "                                label_verb_tool_match_ratio_mapping[label_index] += 1\n",
    "                            elif blip2_verb == label_verb:\n",
    "                                label_verb_match_ratio_mapping[label_index] += 1\n",
    "\n",
    "for dictionary in [label_verb_noun_tool_match_ratio_mapping, label_verb_noun_match_ratio_mapping, label_verb_tool_match_ratio_mapping, label_verb_match_ratio_mapping]:\n",
    "    for label_index in dictionary.keys():\n",
    "        dictionary[label_index] = dictionary[label_index] / float(label_verb_noun_tool_count_mapping[label_index])\n",
    "\n",
    "background_match_ratio = background_match_count / float(background_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 623/623 [00:00<00:00, 1053.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 623/623 [04:41<00:00,  2.21it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 623/623 [00:00<00:00, 169711.72it/s]\n"
     ]
    }
   ],
   "source": [
    "nontemporal_dictionary_matching_clip_id_frame_id_predicted_label_indices_and_scores = dict(pqdm(\n",
    "    [{\"clip_id\": clip_id, \"frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping\": frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping, \"label_verb_noun_tools_mapping\": label_verb_noun_tools_mapping} for clip_id, frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping in clip_id_frame_id_blip2_verb_noun_tool_pair_mapping.items()],\n",
    "    function=nontemporal_dictionary_matching_for_given_clip,\n",
    "    n_jobs=4,\n",
    "    exception_behaviour=\"immediate\",\n",
    "    argument_type=\"kwargs\",\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nontemporal_select_labels_with_maximum_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores: Dict[str, Dict[str, List[float]]], threshold: float):\n",
    "    nontemporal_clip_id_frame_id_predicted_label_indices = dict()\n",
    "    for clip_id, frame_id_predicted_label_indices_and_scores in tqdm(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores.items()):\n",
    "        nontemporal_clip_id_frame_id_predicted_label_indices[clip_id] = dict()\n",
    "        for frame_id, predicted_label_indices_and_scores in frame_id_predicted_label_indices_and_scores.items():\n",
    "            labels_with_maximum_score_higher_than_a_threshold = []\n",
    "            for predicted_label_index, score in predicted_label_indices_and_scores.items():\n",
    "                if score >= threshold:\n",
    "                    labels_with_maximum_score_higher_than_a_threshold.append(predicted_label_index)\n",
    "            nontemporal_clip_id_frame_id_predicted_label_indices[clip_id][frame_id] = labels_with_maximum_score_higher_than_a_threshold\n",
    "    return nontemporal_clip_id_frame_id_predicted_label_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def evaluate_predictions(clip_id_frame_id_predicted_label_indices_mapping: Dict[str, Dict[str, List[str]]], clip_id_frame_id_ground_truth_label_indices_mapping: Dict[str, Dict[str, List[str]]]):\n",
    "    predicted_label_one_hot_vectors = []\n",
    "    ground_truth_label_one_hot_vectors = []\n",
    "\n",
    "    for clip_id, frame_id_ground_truth_label_indices_mapping in tqdm(list(clip_id_frame_id_ground_truth_label_indices_mapping.items())):\n",
    "        for frame_id, ground_truth_label_indices in frame_id_ground_truth_label_indices_mapping.items():\n",
    "            predicted_label_indices = clip_id_frame_id_predicted_label_indices_mapping[clip_id][int(frame_id // 6 * 6)]\n",
    "            predicted_labels_one_hot_vector = np.zeros(len(distinct_ground_truth_labels))\n",
    "            ground_truth_labels_one_hot_vector = np.zeros(len(distinct_ground_truth_labels))\n",
    "\n",
    "            if len(predicted_label_indices) == 0:\n",
    "                print(\"Having zero label index is not possible!!!!\")\n",
    "            else:\n",
    "                for predicted_label_index in predicted_label_indices:\n",
    "                    predicted_labels_one_hot_vector[predicted_label_index] = 1\n",
    "\n",
    "            for ground_truth_label_index in ground_truth_label_indices:\n",
    "                ground_truth_labels_one_hot_vector[ground_truth_label_index] = 1\n",
    "\n",
    "            predicted_label_one_hot_vectors.append(predicted_labels_one_hot_vector)\n",
    "            ground_truth_label_one_hot_vectors.append(ground_truth_labels_one_hot_vector)\n",
    "    # f1_score_per_label = f1_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=None)\n",
    "    weighted_f1 = f1_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=\"weighted\", zero_division=0)\n",
    "    # precision_per_label = precision_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=None)\n",
    "    weighted_precision = precision_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=\"weighted\", zero_division=0)\n",
    "    # recall_per_label = recall_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=None)\n",
    "    weighted_recall = recall_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=\"weighted\", zero_division=0)\n",
    "    return weighted_f1, weighted_precision, weighted_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 53092.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'challenge', 'detect_results', 'retrieve_results'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/487 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0cdba23b-ff3c-4a46-927b-c199050fd26b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     nontemporal_selected_labels_with_individual_score_higher_than_threshold \u001b[38;5;241m=\u001b[39m nontemporal_select_labels_with_individual_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores\u001b[38;5;241m=\u001b[39mclip_id_frame_id_asl_predicted_label_indices_and_scores_mapping, threshold\u001b[38;5;241m=\u001b[39mthreshold)\n\u001b[0;32m----> 3\u001b[0m     weighted_f1, weighted_precision, weighted_recall \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_id_frame_id_predicted_label_indices_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnontemporal_selected_labels_with_individual_score_higher_than_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_id_frame_id_ground_truth_label_indices_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_id_frame_id_ground_truth_label_indices_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mASL Ego4D Baseline | Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(threshold,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_f1,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_precision,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_recall,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(clip_id_frame_id_predicted_label_indices_mapping, clip_id_frame_id_ground_truth_label_indices_mapping)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clip_id, frame_id_ground_truth_label_indices_mapping \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(clip_id_frame_id_ground_truth_label_indices_mapping\u001b[38;5;241m.\u001b[39mitems())):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame_id, ground_truth_label_indices \u001b[38;5;129;01min\u001b[39;00m frame_id_ground_truth_label_indices_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 12\u001b[0m         predicted_label_indices \u001b[38;5;241m=\u001b[39m \u001b[43mclip_id_frame_id_predicted_label_indices_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclip_id\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;28mint\u001b[39m(frame_id \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m)]\n\u001b[1;32m     13\u001b[0m         predicted_labels_one_hot_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(distinct_ground_truth_labels))\n\u001b[1;32m     14\u001b[0m         ground_truth_labels_one_hot_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(distinct_ground_truth_labels))\n",
      "\u001b[0;31mKeyError\u001b[0m: '0cdba23b-ff3c-4a46-927b-c199050fd26b'"
     ]
    }
   ],
   "source": [
    "for threshold in [0.05, 0.10, 0.25, 0.5, 0.75, 1.0]:\n",
    "    nontemporal_selected_labels_with_maximum_score_higher_than_threshold = nontemporal_select_labels_with_maximum_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores=clip_id_frame_id_asl_predicted_label_indices_and_scores_mapping, threshold=threshold)\n",
    "    weighted_f1, weighted_precision, weighted_recall = evaluate_predictions(clip_id_frame_id_predicted_label_indices_mapping=nontemporal_selected_labels_with_maximum_score_higher_than_threshold, clip_id_frame_id_ground_truth_label_indices_mapping=clip_id_frame_id_ground_truth_label_indices_mapping)\n",
    "    print(f\"ASL Ego4D Baseline | Threshold: {np.round(threshold, 2)} | Weighted F1 Score: {np.round(weighted_f1, 2)} | Weighted Precision: {np.round(weighted_precision, 2)} | Weighted Recall: {np.round(weighted_recall, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [00:17<00:00, 35.37it/s]\n",
      "100%|██████████| 487/487 [00:23<00:00, 20.51it/s]\n",
      "/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP2 Dictionary Matching | Threshold: 0.25 | Weighted Average F1 Score: 0.19 | Weighted Average Precision: 0.35 | Weighted Average Recall: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [00:17<00:00, 35.51it/s]\n",
      "100%|██████████| 487/487 [00:18<00:00, 26.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     nontemporal_selected_labels_with_individual_score_higher_than_threshold \u001b[38;5;241m=\u001b[39m nontemporal_select_labels_with_individual_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores\u001b[38;5;241m=\u001b[39mnontemporal_dictionary_matching_clip_id_frame_id_predicted_label_indices_and_scores, threshold\u001b[38;5;241m=\u001b[39mthreshold)\n\u001b[0;32m----> 3\u001b[0m     weighted_f1, weighted_precision, weighted_recall \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_id_frame_id_predicted_label_indices_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnontemporal_selected_labels_with_individual_score_higher_than_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_id_frame_id_ground_truth_label_indices_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_id_frame_id_ground_truth_label_indices_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLIP2 Dictionary Matching | Threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(threshold,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted Average F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_f1,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted Average Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_precision,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Weighted Average Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(weighted_recall,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(clip_id_frame_id_predicted_label_indices_mapping, clip_id_frame_id_ground_truth_label_indices_mapping)\u001b[0m\n\u001b[1;32m     24\u001b[0m         ground_truth_label_one_hot_vectors\u001b[38;5;241m.\u001b[39mappend(ground_truth_labels_one_hot_vector)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# f1_score_per_label = f1_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=None)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m weighted_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mground_truth_label_one_hot_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredicted_label_one_hot_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# precision_per_label = precision_score(y_true=ground_truth_label_one_hot_vectors, y_pred=predicted_label_one_hot_vectors, average=None)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m weighted_precision \u001b[38;5;241m=\u001b[39m precision_score(y_true\u001b[38;5;241m=\u001b[39mground_truth_label_one_hot_vectors, y_pred\u001b[38;5;241m=\u001b[39mpredicted_label_one_hot_vectors, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[1;32m   1098\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1239\u001b[0m         y_true,\n\u001b[1;32m   1240\u001b[0m         y_pred,\n\u001b[1;32m   1241\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1242\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1243\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1244\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1245\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1246\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1247\u001b[0m     )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     {\n\u001b[1;32m   1252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m ):\n\u001b[1;32m   1280\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \n\u001b[1;32m   1282\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[39m    0.38...\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1412\u001b[0m         y_true,\n\u001b[1;32m   1413\u001b[0m         y_pred,\n\u001b[1;32m   1414\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m   1415\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1416\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1417\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1418\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1419\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1420\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1421\u001b[0m     )\n\u001b[1;32m   1422\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1497\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1500\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/multiclass.py:310\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    308\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be class \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseSeries\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseArray\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 310\u001b[0m \u001b[39mif\u001b[39;00m is_multilabel(y):\n\u001b[1;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[39m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/multiclass.py:188\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    183\u001b[0m         \u001b[39mlen\u001b[39m(y\u001b[39m.\u001b[39mdata) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    184\u001b[0m         \u001b[39mor\u001b[39;00m (labels\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m (labels\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m labels))\n\u001b[1;32m    185\u001b[0m         \u001b[39mand\u001b[39;00m (y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m _is_integral_float(labels))  \u001b[39m# bool, int, uint\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     labels \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39;49munique_values(y)\n\u001b[1;32m    190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(labels) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m         y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mbiu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m _is_integral_float(labels)  \u001b[39m# bool, int, uint\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     )\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/sklearn/utils/_array_api.py:262\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/data/aarslan/mambaforge/envs/mq_analysis/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for threshold in [0.05, 0.10, 0.25, 0.5, 0.75, 1.0]:\n",
    "    nontemporal_selected_labels_with_maximum_score_higher_than_threshold = nontemporal_select_labels_with_maximum_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores=nontemporal_dictionary_matching_clip_id_frame_id_predicted_label_indices_and_scores, threshold=threshold)\n",
    "    weighted_f1, weighted_precision, weighted_recall = evaluate_predictions(clip_id_frame_id_predicted_label_indices_mapping=nontemporal_selected_labels_with_maximum_score_higher_than_threshold, clip_id_frame_id_ground_truth_label_indices_mapping=clip_id_frame_id_ground_truth_label_indices_mapping)\n",
    "    print(f\"BLIP2 Dictionary Matching | Threshold: {np.round(threshold, 2)} | Weighted F1 Score: {np.round(weighted_f1, 2)} | Weighted Precision: {np.round(weighted_precision, 2)} | Weighted Recall: {np.round(weighted_recall, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontemporal_sbert_embedding_clip_id_frame_id_predicted_label_indices_and_scores = dict()\n",
    "for clip_id, frame_id_blip2_verb_noun_tool_pair_mapping in tqdm(list(clip_id_frame_id_blip2_verb_noun_tool_pair_mapping.items())):\n",
    "    nontemporal_sbert_embedding_clip_id_frame_id_predicted_label_indices_and_scores[clip_id] = nontemporal_sbert_embedding_for_given_clip(clip_id=clip_id, frame_id_blip2_question_answer_verb_noun_tool_pairs_mapping=frame_id_blip2_verb_noun_tool_pair_mapping, label_verb_noun_tools_mapping=label_verb_noun_tools_mapping)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.05, 0.10, 0.25, 0.5, 0.75, 1.0]:\n",
    "    nontemporal_selected_labels_with_maximum_score_higher_than_threshold = nontemporal_select_labels_with_maximum_score_higher_than_threshold(nontemporal_clip_id_frame_id_predicted_label_indices_and_scores=nontemporal_sbert_embedding_clip_id_frame_id_predicted_label_indices_and_scores, threshold=threshold)\n",
    "    weighted_f1, weighted_precision, weighted_recall = evaluate_predictions(clip_id_frame_id_predicted_label_indices_mapping=nontemporal_selected_labels_with_maximum_score_higher_than_threshold, clip_id_frame_id_ground_truth_label_indices_mapping=clip_id_frame_id_ground_truth_label_indices_mapping)\n",
    "    print(f\"BLIP2 SBERT Embedding | Threshold: {np.round(threshold, 2)} | Weighted F1 Score: {np.round(weighted_f1, 2)} | Weighted Precision: {np.round(weighted_precision, 2)} | Weighted Recall: {np.round(weighted_recall, 2)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('mq_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7baf97c684abb9a3f3dba5fbfca0f2f069a7ab5cf394abaf3794cf37d30c0a2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
